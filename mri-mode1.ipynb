{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1183165,"sourceType":"datasetVersion","datasetId":672377}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import image_dataset_from_directory\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n\n# Function to create the CNN model\ndef create_cnn_model(input_shape=(224, 224, 3), num_classes=4):\n    cnn_input = layers.Input(shape=input_shape)\n    \n    x = layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.001))(cnn_input)\n    x = layers.BatchNormalization()(x)\n    \n    x = layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001))(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.MaxPooling2D(2, 2)(x)\n    x = layers.Dropout(0.3)(x)\n\n    x = layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001))(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.MaxPooling2D(2, 2)(x)\n    x = layers.Dropout(0.4)(x)\n\n    x = layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001))(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.MaxPooling2D(2, 2)(x)\n\n    x = layers.Flatten()(x)\n    x = layers.Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.5)(x)\n\n    cnn_output = layers.Dense(num_classes, activation='softmax')(x)\n\n    cnn_model = Model(inputs=cnn_input, outputs=cnn_output)\n    cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    return cnn_model\n\n# Instantiate the CNN model\ncnn_model = create_cnn_model()\n\n# Summary of the model\ncnn_model.summary()\n\n# Data Augmentation\ntrain_datagen = image_dataset_from_directory(\n    \"/kaggle/input/brain-tumor-classification-mri/Training\",\n    image_size=(224, 224),\n    batch_size=32,\n    label_mode=\"categorical\",\n    validation_split=0.2,\n    subset='training',\n    seed=123\n)\n\nval_datagen = image_dataset_from_directory(\n    \"/kaggle/input/brain-tumor-classification-mri/Training\",\n    image_size=(224, 224),\n    batch_size=32,\n    label_mode=\"categorical\",\n    validation_split=0.2,\n    subset='validation',\n    seed=123\n)\n\ntest_datagen = image_dataset_from_directory(\n    \"/kaggle/input/brain-tumor-classification-mri/Testing\",\n    image_size=(224, 224),\n    batch_size=32,\n    label_mode=\"categorical\"\n)\n\n# Define callbacks for learning rate scheduling and early stopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n\n# Train the CNN model\nprint(\"Training CNN model with early stopping, learning rate scheduler, and data augmentation...\")\ncnn_model.fit(train_datagen, validation_data=val_datagen, epochs=30, callbacks=[early_stopping, lr_scheduler])\n\n# Convert dataset to arrays for feature extraction\ndef dataset_to_arrays(dataset):\n    images = []\n    labels = []\n    for image_batch, label_batch in dataset:\n        images.append(image_batch.numpy())\n        labels.append(label_batch.numpy())\n    return np.concatenate(images, axis=0), np.concatenate(labels, axis=0)\n\nX_train, y_train = dataset_to_arrays(train_datagen)\nX_val, y_val = dataset_to_arrays(val_datagen)\nX_test, y_test = dataset_to_arrays(test_datagen)\n\n# Extract features using the trained CNN model\nprint(\"Extracting features using CNN...\")\ncnn_feature_extractor = Model(inputs=cnn_model.input, outputs=cnn_model.layers[-4].output)  # Extract before Dense layer\ncnn_features_train = cnn_feature_extractor.predict(X_train)\ncnn_features_val = cnn_feature_extractor.predict(X_val)\ncnn_features_test = cnn_feature_extractor.predict(X_test)\n\n# Reshape CNN features for SVM and Random Forest compatibility\ncnn_features_train = cnn_features_train.reshape(cnn_features_train.shape[0], -1)\ncnn_features_val = cnn_features_val.reshape(cnn_features_val.shape[0], -1)\ncnn_features_test = cnn_features_test.reshape(cnn_features_test.shape[0], -1)\n\n# Train the SVM model\nprint(\"Training SVM model...\")\nsvm_model = SVC(kernel='linear', probability=True)\nsvm_model.fit(cnn_features_train, np.argmax(y_train, axis=1))\n\n# Train the Random Forest model\nprint(\"Training Random Forest model...\")\nrf_model = RandomForestClassifier(n_estimators=100)\nrf_model.fit(cnn_features_train, np.argmax(y_train, axis=1))\n\n# Create an ensemble model using SVM and Random Forest\nprint(\"Creating ensemble model with SVM and Random Forest...\")\nensemble_model = VotingClassifier(estimators=[\n    ('svm', svm_model),\n    ('rf', rf_model)\n], voting='soft')\n\n# Train the ensemble model\nensemble_model.fit(cnn_features_train, np.argmax(y_train, axis=1))\n\n# Evaluation function for all models\ndef evaluate_model(model, X_test, y_test):\n    if isinstance(model, Model):\n        y_pred = np.argmax(model.predict(X_test), axis=1)\n    else:\n        y_pred = model.predict(X_test)\n    y_true = np.argmax(y_test, axis=1)\n\n    accuracy = accuracy_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred, average='weighted')\n    recall = recall_score(y_true, y_pred, average='weighted')\n    f1 = f1_score(y_true, y_pred, average='weighted')\n\n    return accuracy, precision, recall, f1\n\n# Evaluate the CNN model\nprint(\"Evaluating CNN model...\")\ncnn_accuracy, cnn_precision, cnn_recall, cnn_f1 = evaluate_model(cnn_model, X_test, y_test)\n\n# Evaluate the SVM model\nprint(\"Evaluating SVM model...\")\nsvm_accuracy, svm_precision, svm_recall, svm_f1 = evaluate_model(svm_model, cnn_features_test, y_test)\n\n# Evaluate the Random Forest model\nprint(\"Evaluating Random Forest model...\")\nrf_accuracy, rf_precision, rf_recall, rf_f1 = evaluate_model(rf_model, cnn_features_test, y_test)\n\n# Evaluate the ensemble model\nprint(\"Evaluating Ensemble model...\")\nensemble_accuracy, ensemble_precision, ensemble_recall, ensemble_f1 = evaluate_model(ensemble_model, cnn_features_test, y_test)\n\n# Print results for all models\nprint(f\"\\nCNN Model - Accuracy: {cnn_accuracy:.4f}, Precision: {cnn_precision:.4f}, Recall: {cnn_recall:.4f}, F1 Score: {cnn_f1:.4f}\")\nprint(f\"SVM Model - Accuracy: {svm_accuracy:.4f}, Precision: {svm_precision:.4f}, Recall: {svm_recall:.4f}, F1 Score: {svm_f1:.4f}\")\nprint(f\"Random Forest Model - Accuracy: {rf_accuracy:.4f}, Precision: {rf_precision:.4f}, Recall: {rf_recall:.4f}, F1 Score: {rf_f1:.4f}\")\nprint(f\"Ensemble Model - Accuracy: {ensemble_accuracy:.4f}, Precision: {ensemble_precision:.4f}, Recall: {ensemble_recall:.4f}, F1 Score: {ensemble_f1:.4f}\")\n\n# Print the classification report for the ensemble model\nprint(\"\\nEnsemble Model Classification Report:\")\nprint(classification_report(np.argmax(y_test, axis=1), ensemble_model.predict(cnn_features_test)))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-03T12:13:24.782858Z","iopub.execute_input":"2025-01-03T12:13:24.783193Z","iopub.status.idle":"2025-01-03T12:20:57.331677Z","shell.execute_reply.started":"2025-01-03T12:13:24.783167Z","shell.execute_reply":"2025-01-03T12:20:57.330705Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m220\u001b[0m, \u001b[38;5;34m220\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m220\u001b[0m, \u001b[38;5;34m220\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m108\u001b[0m, \u001b[38;5;34m108\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m73,856\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m108\u001b[0m, \u001b[38;5;34m108\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │           \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m44,302,848\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m2,052\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">44,302,848</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,052</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,549,188\u001b[0m (169.94 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,549,188</span> (169.94 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,547,460\u001b[0m (169.94 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,547,460</span> (169.94 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,728\u001b[0m (6.75 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> (6.75 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Found 2870 files belonging to 4 classes.\nUsing 2296 files for training.\nFound 2870 files belonging to 4 classes.\nUsing 574 files for validation.\nFound 394 files belonging to 4 classes.\nTraining CNN model with early stopping, learning rate scheduler, and data augmentation...\nEpoch 1/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 555ms/step - accuracy: 0.6150 - loss: 3.4520 - val_accuracy: 0.3449 - val_loss: 4.7666 - learning_rate: 0.0010\nEpoch 2/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 173ms/step - accuracy: 0.7717 - loss: 2.9969 - val_accuracy: 0.7300 - val_loss: 2.9569 - learning_rate: 0.0010\nEpoch 3/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 177ms/step - accuracy: 0.8421 - loss: 2.5481 - val_accuracy: 0.6446 - val_loss: 2.7104 - learning_rate: 0.0010\nEpoch 4/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 175ms/step - accuracy: 0.8729 - loss: 2.1167 - val_accuracy: 0.5157 - val_loss: 4.1123 - learning_rate: 0.0010\nEpoch 5/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 173ms/step - accuracy: 0.8563 - loss: 2.1123 - val_accuracy: 0.2770 - val_loss: 10.8750 - learning_rate: 0.0010\nEpoch 6/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 172ms/step - accuracy: 0.8669 - loss: 1.9882 - val_accuracy: 0.3606 - val_loss: 7.8458 - learning_rate: 5.0000e-04\nEpoch 7/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 172ms/step - accuracy: 0.9264 - loss: 1.7617 - val_accuracy: 0.5976 - val_loss: 4.4499 - learning_rate: 5.0000e-04\nEpoch 8/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 176ms/step - accuracy: 0.9553 - loss: 1.5164 - val_accuracy: 0.8641 - val_loss: 1.7386 - learning_rate: 2.5000e-04\nEpoch 9/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 176ms/step - accuracy: 0.9807 - loss: 1.3137 - val_accuracy: 0.8589 - val_loss: 1.5254 - learning_rate: 2.5000e-04\nEpoch 10/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 176ms/step - accuracy: 0.9771 - loss: 1.2019 - val_accuracy: 0.8990 - val_loss: 1.3581 - learning_rate: 2.5000e-04\nEpoch 11/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 172ms/step - accuracy: 0.9845 - loss: 1.0844 - val_accuracy: 0.8188 - val_loss: 1.4902 - learning_rate: 2.5000e-04\nEpoch 12/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 172ms/step - accuracy: 0.9812 - loss: 1.0167 - val_accuracy: 0.7997 - val_loss: 1.5685 - learning_rate: 2.5000e-04\nEpoch 13/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 176ms/step - accuracy: 0.9819 - loss: 0.9790 - val_accuracy: 0.9059 - val_loss: 1.1483 - learning_rate: 1.2500e-04\nEpoch 14/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 172ms/step - accuracy: 0.9923 - loss: 0.9013 - val_accuracy: 0.9077 - val_loss: 1.1587 - learning_rate: 1.2500e-04\nEpoch 15/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 176ms/step - accuracy: 0.9935 - loss: 0.8489 - val_accuracy: 0.9042 - val_loss: 1.0929 - learning_rate: 1.2500e-04\nEpoch 16/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 176ms/step - accuracy: 0.9941 - loss: 0.8071 - val_accuracy: 0.8972 - val_loss: 1.0575 - learning_rate: 1.2500e-04\nEpoch 17/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 176ms/step - accuracy: 0.9923 - loss: 0.7662 - val_accuracy: 0.9007 - val_loss: 1.0264 - learning_rate: 1.2500e-04\nEpoch 18/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 172ms/step - accuracy: 0.9989 - loss: 0.7194 - val_accuracy: 0.8990 - val_loss: 1.0457 - learning_rate: 1.2500e-04\nEpoch 19/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 172ms/step - accuracy: 0.9977 - loss: 0.6847 - val_accuracy: 0.8815 - val_loss: 1.0537 - learning_rate: 1.2500e-04\nEpoch 20/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 176ms/step - accuracy: 0.9935 - loss: 0.6657 - val_accuracy: 0.8955 - val_loss: 0.9957 - learning_rate: 6.2500e-05\nEpoch 21/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 175ms/step - accuracy: 0.9946 - loss: 0.6494 - val_accuracy: 0.9129 - val_loss: 0.9693 - learning_rate: 6.2500e-05\nEpoch 22/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 176ms/step - accuracy: 0.9994 - loss: 0.6233 - val_accuracy: 0.9181 - val_loss: 0.9264 - learning_rate: 6.2500e-05\nEpoch 23/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 176ms/step - accuracy: 0.9998 - loss: 0.6010 - val_accuracy: 0.9199 - val_loss: 0.9117 - learning_rate: 6.2500e-05\nEpoch 24/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 176ms/step - accuracy: 0.9976 - loss: 0.5887 - val_accuracy: 0.9111 - val_loss: 0.8730 - learning_rate: 6.2500e-05\nEpoch 25/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 176ms/step - accuracy: 0.9987 - loss: 0.5723 - val_accuracy: 0.9233 - val_loss: 0.8689 - learning_rate: 6.2500e-05\nEpoch 26/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 176ms/step - accuracy: 0.9988 - loss: 0.5553 - val_accuracy: 0.9129 - val_loss: 0.8601 - learning_rate: 6.2500e-05\nEpoch 27/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 176ms/step - accuracy: 0.9996 - loss: 0.5379 - val_accuracy: 0.9164 - val_loss: 0.8542 - learning_rate: 6.2500e-05\nEpoch 28/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 176ms/step - accuracy: 0.9985 - loss: 0.5245 - val_accuracy: 0.9181 - val_loss: 0.8106 - learning_rate: 6.2500e-05\nEpoch 29/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 172ms/step - accuracy: 0.9990 - loss: 0.5097 - val_accuracy: 0.9059 - val_loss: 0.8701 - learning_rate: 6.2500e-05\nEpoch 30/30\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 172ms/step - accuracy: 0.9971 - loss: 0.5006 - val_accuracy: 0.9111 - val_loss: 0.8455 - learning_rate: 6.2500e-05\nExtracting features using CNN...\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step\nTraining SVM model...\nTraining Random Forest model...\nCreating ensemble model with SVM and Random Forest...\nEvaluating CNN model...\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step\nEvaluating SVM model...\nEvaluating Random Forest model...\nEvaluating Ensemble model...\n\nCNN Model - Accuracy: 0.7411, Precision: 0.8025, Recall: 0.7411, F1 Score: 0.6937\nSVM Model - Accuracy: 0.7259, Precision: 0.8027, Recall: 0.7259, F1 Score: 0.6764\nRandom Forest Model - Accuracy: 0.7081, Precision: 0.7967, Recall: 0.7081, F1 Score: 0.6619\nEnsemble Model - Accuracy: 0.7208, Precision: 0.7998, Recall: 0.7208, F1 Score: 0.6735\n\nEnsemble Model Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      0.19      0.32       100\n           1       0.70      0.94      0.80       115\n           2       0.64      0.98      0.77       105\n           3       0.92      0.73      0.81        74\n\n    accuracy                           0.72       394\n   macro avg       0.81      0.71      0.68       394\nweighted avg       0.80      0.72      0.67       394\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Predict and evaluate the CNN model\ncnn_predictions = cnn_model.predict(X_test)\ncnn_pred_labels = np.argmax(cnn_predictions, axis=1)\ncnn_report = classification_report(np.argmax(y_test, axis=1), cnn_pred_labels, target_names=train_data.class_names)\n\n# Predict and evaluate the SVM model\nsvm_pred_labels = svm_model.predict(cnn_features_test)\nsvm_report = classification_report(np.argmax(y_test, axis=1), svm_pred_labels, target_names=train_data.class_names)\n\n# Predict and evaluate the Random Forest model\nrf_pred_labels = rf_model.predict(cnn_features_test)\nrf_report = classification_report(np.argmax(y_test, axis=1), rf_pred_labels, target_names=train_data.class_names)\n\n# Predict and evaluate the Ensemble model\nensemble_pred_labels = ensemble_model.predict(cnn_features_test)\nensemble_report = classification_report(np.argmax(y_test, axis=1), ensemble_pred_labels, target_names=train_data.class_names)\n\n# Print evaluation reports\nprint(\"CNN Model Classification Report:\")\nprint(cnn_report)\n\nprint(\"SVM Model Classification Report:\")\nprint(svm_report)\n\nprint(\"Random Forest Model Classification Report:\")\nprint(rf_report)\n\nprint(\"Ensemble Model Classification Report:\")\nprint(ensemble_report)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nimport numpy as np\n\n# Function to preprocess the new image\ndef preprocess_image(image_path, target_size=(150, 150)):\n    img = image.load_img(image_path, target_size=target_size)\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n    img_array = img_array / 255.0  # Normalize\n    return img_array\n\n# Load the new image\nnew_image_path = '/kaggle/input/brain-tumor-classification-mri/Testing/pituitary_tumor/image(15).jpg'  # Replace with the path to your new image\nnew_image = preprocess_image(new_image_path)\n\n# Extract features from the new image using the CNN model\ncnn_features_new = cnn_feature_extractor.predict(new_image)\ncnn_features_new = cnn_features_new.reshape(cnn_features_new.shape[0], -1)\n\n# Predict using the ensemble model\npredicted_class = ensemble_model.predict(cnn_features_new)\n\n# Map the predicted class index to the actual class name (assuming class labels are in order)\nclass_labels = train_data.class_names\npredicted_label = class_labels[predicted_class[0]]\n\nprint(f\"Predicted class: {predicted_label}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract training history from CNN model\nhistory = cnn_model.history.history  # Access the 'history' attribute\n\n# Plot Training and Validation Accuracy\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(history['accuracy'], label='Training Accuracy')\nplt.plot(history['val_accuracy'], label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Plot Training and Validation Loss\nplt.subplot(1, 2, 2)\nplt.plot(history['loss'], label='Training Loss')\nplt.plot(history['val_loss'], label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the indices of the top 10 important features\ntop_features_indices = np.argsort(feature_importances)[-10:]\n\n# Plot top 10 important features\nplt.figure(figsize=(10, 6))\nplt.barh(range(10), feature_importances[top_features_indices])\nplt.title('Top 10 Feature Importance (Random Forest)')\nplt.xlabel('Importance')\nplt.ylabel('Feature Index')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n# Generate confusion matrix\ny_pred = ensemble_model.predict(cnn_features_test)\ncm = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=train_data.class_names, yticklabels=train_data.class_names)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cnn_model.save('cnn_model.h5')  # Save the CNN model to a file\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\n\n# Save the Random Forest model\njoblib.dump(rf_model, 'rf_model.pkl')\n\n# Save the SVM model\njoblib.dump(svm_model, 'svm_model.pkl')\n\n# Save the ensemble model\njoblib.dump(ensemble_model, 'ensemble_model.pkl')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}